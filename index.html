<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Anonymous Audio Demo</title>
    <link rel="stylesheet" href="styles.css">
    <style>
        /* 新增样式：优化作者与单位的排版 */
        .authors-list {
            margin: 10px 0;
            line-height: 1.5;
        }
        .affiliation-list {
            margin: 10px 0;
            padding-left: 20px; /* 缩进对齐编号 */
            line-height: 1.6;
        }
        .affiliation-item {
            margin-bottom: 8px; /* 单位之间增加间距 */
        }
    </style>
</head>
<body>
    <div class="page-header">
        <h1>Submission Demo of the manuscript ``BridgeVoC: Revitalizing Neural Vocoder from a Restoration Perspective</h1>
        
        <div class="authors">
            <!-- 作者列表：用数字标注所属单位 -->
            <p class="authors-list">
                Andong Li<sup>1,2</sup>, Tong Lei<sup>3</sup>, Rilin Chen<sup>3</sup>, Kai Li<sup>4</sup>, 
                Meng Yu<sup>3</sup>, Xiaodong Li<sup>1,2</sup>, Dong Yu<sup>3</sup>, Chengshi Zheng<sup>1,2</sup>
            </p>
            
            <!-- 单位说明：对应数字的详细单位信息 -->
            <div class="affiliation-list">
                <p class="affiliation-item"><sup>1</sup> Institute of Acoustics, Chinese Academy of Sciences, Beijing, China.</p> 
                <p class="affiliation-item"><sup>2</sup> University of Chinese Academy of Sciences, Beijing, China.</p>
                <p class="affiliation-item"><sup>3</sup> Tencent AI Lab</p>
                <p class="affiliation-item"><sup>4</sup> Tsinghua University, Beijing, China.</p>
            </div>
        </div>
        
        <div class="abstract">
            <h2>Abstract</h2>
            <p> 
                Despite significant advances in neural vocoders using diffusion models and their variants, these methods, unfortunately, inherently suffer from a performance-inference dilemma, 
                which stems from the iterative nature in the reverse inference process. This hurdle can heavily hinder the development of this field. To address this challenge, in this paper, we 
                revisit the neural vocoder task through the lens of audio restoration and propose a novel diffusion vocoder called BridgeVoC. Specifically, by rank analysis, we compare the rank 
                characteristics of Mel-spectrum with other common acoustic degradation factors, and cast the vocoder task as a specialized case of audio restoration, where the range-space spectral (RSS) 
                surrogate of the target spectrum serves as the degraded input. Based on that, we introduce the Schrodinger bridge framework for diffusion modeling, which defines the RSS and target 
                spectrum as dual endpoints of the stochastic generation trajectory. Further, to fully utilize the hierarchical prior of subbands in the time-frequency (T-F) domain, we elaborately 
                devise a novel subband-aware convolutional diffusion network as the data predictor, where subbands are divided following an uneven strategy, and convolutional-style attention module 
                is employed with large kernels for efficient T-F contextual modeling. To enable single-step inference, we propose an omnidirectional distillation loss to facilitate effective
                information transfer from the teacher to student models, and the performance is improved by combining target-related and bijective consistency losses. Comprehensive experiments 
                are conducted on various benchmarks and out-of-distribution datasets. Quantitative and qualitative results show that while enjoying fewer parameters, lower computational cost and 
                competitive inference speed, the proposed BridgeVoC yields state-of-theart performance over existing advanced GAN-, DDPM- and flow-matching-based baselines with only 4 sampling steps. And
                consistent superiority is still achieved with single-step inference.
            </p>
        </div>
    </div>

    <div class="sections-wrapper">
        <div id="aishell3" class="section-container">
            <h2>AISHELL3 dataset</h2>
        </div>

        <div id="ears" class="section-container">
            <h2>EARS dataset</h2>
        </div>

        <div id="musdb18" class="section-container">
            <h2>MUSDB18 vocals dataset</h2>
        </div>
    </div>

    <script src="scripts.js"></script>
</body>
</html>